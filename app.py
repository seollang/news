import streamlit as st
import requests
from bs4 import BeautifulSoup
from transformers import pipeline
import re
import time

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="IT News Summarizer", page_icon="ğŸ“°", layout="wide")

# ë‰´ìŠ¤ ë§í¬ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_news_links():
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36",
        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"
    }
    try:
        response = requests.get("https://news.naver.com/section/105", headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, "html.parser")
        # IT/ê³¼í•™ ì„¹ì…˜ì˜ ê¸°ì‚¬ ì»¨í…Œì´ë„ˆ ì°¾ê¸°
        articles = soup.find_all("div", class_="sa_text")
        news_links = []
        seen_urls = set()
        for article in articles:
            link = article.find("a", href=re.compile(r'n\.news\.naver\.com/mnews/article/\d+/\d+'))
            title_tag = article.find("strong", class_="sa_text_strong")
            if link and title_tag:
                href = link.get("href")
                if href and href not in seen_urls:
                    if not href.startswith("http"):
                        href = "https://news.naver.com" + href
                    title = title_tag.get_text(strip=True) or "ì œëª© ì—†ìŒ"
                    st.write(f"ë””ë²„ê¹…: ë§í¬={href}, ì œëª©={title}")
                    news_links.append({"title": title, "url": href})
                    seen_urls.add(href)
        st.write(f"ë””ë²„ê¹…: {len(news_links)}ê°œì˜ ë‰´ìŠ¤ ë§í¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        return news_links[:5]  # ìµœëŒ€ 5ê°œ ê¸°ì‚¬
    except Exception as e:
        st.error(f"ë‰´ìŠ¤ ë§í¬ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# ë‰´ìŠ¤ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_article_content(url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"
    }
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, "html.parser")
        content = soup.find("article", {"id": "dic_area"})
        return content.get_text(strip=True) if content else ""
    except Exception as e:
        st.error(f"ê¸°ì‚¬ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ""

# ìš”ì•½ í•¨ìˆ˜
@st.cache_resource
def get_summarizer():
    return pipeline("summarization", model="gogamza/kobart-summarization")

def summarize_text(text):
    try:
        summarizer = get_summarizer()
        max_input_length = 512
        summary = summarizer(text[:max_input_length], max_length=150, min_length=30, do_sample=False)
        return summary[0]['summary_text']
    except Exception as e:
        st.error(f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return ""

# ë©”ì¸ ì•±
def main():
    st.title("ğŸ“° IT ë‰´ìŠ¤ ìš”ì•½ê¸°")
    st.markdown("ë„¤ì´ë²„ IT/ê³¼í•™ ë‰´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ê°€ì ¸ì™€ AIë¡œ ìš”ì•½í•©ë‹ˆë‹¤.")

    # ë‰´ìŠ¤ ë§í¬ ê°€ì ¸ì˜¤ê¸°
    with st.spinner("ë‰´ìŠ¤ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
        news_links = get_news_links()

    if not news_links:
        st.warning("ê°€ì ¸ì˜¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        return

    # ë‰´ìŠ¤ ëª©ë¡ í‘œì‹œ
    for news in news_links:
        with st.expander(f"ğŸ—ï¸ {news['title']}"):
            st.write(f"[ì›ë¬¸ ì½ê¸°]({news['url']})")
            with st.spinner("ê¸°ì‚¬ë¥¼ ìš”ì•½í•˜ëŠ” ì¤‘..."):
                article = get_article_content(news['url'])
                if article:
                    summary = summarize_text(article)
                    if summary:
                        st.markdown("### ìš”ì•½")
                        st.write(summary)
                    else:
                        st.warning("ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.warning("ê¸°ì‚¬ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
